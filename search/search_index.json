{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"poetry-analysis","text":"<p>Rule-based tool to extract repetition patterns and other lyric features from poetry, or other text data where the newline is a meaningful segment boundary.</p> <p>Lyric features that can be extracted with this tool includes</p> <ul> <li>end rhyme schemes</li> <li>alliteration</li> <li>anaphora</li> <li>lyrical subject</li> </ul> <p>This tool was developed for the NORN project.</p> <p>It was developed alongside NORN Poems, a corpus of Norwegian poetry from the 1890's, which is freely available as TEI <code>.xml</code> and plain <code>.txt</code> files.</p> <ul> <li>Github repository: https://github.com/norn-uio/poetry-analysis/</li> <li>Documentation https://norn-uio.github.io/poetry-analysis/</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install poetry-analysis\n</code></pre>"},{"location":"api_alliteration/","title":"Alliteration","text":""},{"location":"api_alliteration/#poetry_analysis.alliteration","title":"<code>poetry_analysis.alliteration</code>","text":"<p>The definition of alliteration that we use here is the repetition of word-initial consonants or consonant clusters.</p>"},{"location":"api_alliteration/#poetry_analysis.alliteration.count_alliteration","title":"<code>count_alliteration(text)</code>","text":"<p>Count the number of times the same word-initial letter occurs in a text.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; text = \"Sirius som seer\"\n&gt;&gt;&gt; count_alliteration(text)\n{'s': 3}\n</code></pre> Source code in <code>src/poetry_analysis/alliteration.py</code> <pre><code>def count_alliteration(text: str) -&gt; dict:\n    \"\"\"Count the number of times the same word-initial letter occurs in a text.\n\n    Examples:\n        &gt;&gt;&gt; text = \"Sirius som seer\"\n        &gt;&gt;&gt; count_alliteration(text)\n        {'s': 3}\n    \"\"\"\n    words = text.split()\n    initial_counts = {}\n\n    for word in words:\n        initial_letter = word[0].lower()\n        if initial_letter in initial_counts:\n            initial_counts[initial_letter] += 1\n        else:\n            initial_counts[initial_letter] = 1\n\n    alliteration_count = {letter: count for letter, count in initial_counts.items() if count &gt; 1}\n\n    return alliteration_count\n</code></pre>"},{"location":"api_alliteration/#poetry_analysis.alliteration.extract_alliteration","title":"<code>extract_alliteration(text)</code>","text":"<p>Extract words that start with the same letter from a text.</p> <p>NB! This function is case-insensitive and compares e.g. S to s as the same letter.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>list</code> <p>A list of strings, where each string is a line of text.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; text = ['Stjerneklare Septembernat Sees Sirius', 'Sydhimlens smukkeste Stjerne']\n&gt;&gt;&gt; extract_alliteration(text)\n[{'line': 0, 'symbol': 's', 'count': 4, 'words': ['Stjerneklare', 'Septembernat', 'Sees', 'Sirius']}, {'line': 1, 'symbol': 's', 'count': 3, 'words': ['Sydhimlens', 'smukkeste', 'Stjerne']}]\n</code></pre> Source code in <code>src/poetry_analysis/alliteration.py</code> <pre><code>def extract_alliteration(text: list[str]) -&gt; list[dict]:\n    \"\"\"Extract words that start with the same letter from a text.\n\n    NB! This function is case-insensitive and compares e.g. S to s as the same letter.\n\n    Args:\n        text (list): A list of strings, where each string is a line of text.\n\n    Examples:\n        &gt;&gt;&gt; text = ['Stjerneklare Septembernat Sees Sirius', 'Sydhimlens smukkeste Stjerne']\n        &gt;&gt;&gt; extract_alliteration(text)\n        [{'line': 0, 'symbol': 's', 'count': 4, 'words': ['Stjerneklare', 'Septembernat', 'Sees', 'Sirius']}, {'line': 1, 'symbol': 's', 'count': 3, 'words': ['Sydhimlens', 'smukkeste', 'Stjerne']}]\n    \"\"\"\n\n    alliterations = []\n\n    for i, line in enumerate(text):\n        words = line.split() if isinstance(line, str) else line\n        seen = {}\n        for j, word in enumerate(words):\n            initial_letter = word[0].lower()\n            if not initial_letter.isalpha():\n                continue\n\n            if initial_letter in seen:\n                seen[initial_letter].append(word)\n            else:\n                seen[initial_letter] = [word]\n\n            if (j == len(words) - 1) and any(len(v) &gt; 1 for v in seen.values()):\n                alliteration_symbols = [k for k, v in seen.items() if len(v) &gt; 1]\n                for symbol in alliteration_symbols:\n                    alliterations.append(\n                        {\n                            \"line\": i,\n                            \"symbol\": symbol,\n                            \"count\": len(seen[symbol]),\n                            \"words\": seen[symbol],\n                        }\n                    )\n\n    return alliterations\n</code></pre>"},{"location":"api_alliteration/#poetry_analysis.alliteration.find_line_alliterations","title":"<code>find_line_alliterations(text, allowed_intervening_words=None)</code>","text":"<p>Find alliterations on a line.</p> Source code in <code>src/poetry_analysis/alliteration.py</code> <pre><code>def find_line_alliterations(text: str | list, allowed_intervening_words: list | None = None):\n    \"\"\"Find alliterations on a line.\"\"\"\n    if allowed_intervening_words is None:\n        allowed_intervening_words = [\"og\", \"i\", \"er\"]\n\n    if isinstance(text, list):\n        words = text\n    elif isinstance(text, str):\n        words = utils.normalize(text)\n    elif text is None:\n        words = list()\n\n    # Stores {initial_letter: [indices_of_words_starting_with_this_letter]}\n    seen = {}\n    for j, word_token in enumerate(words):\n        if not word_token:  # Handle potential empty strings from tokenizer\n            continue\n        # Ensure word_token is not empty before accessing word_token[0]\n        if not word_token[0].isalpha():\n            continue\n        initial_letter = word_token[0].lower()\n\n        if initial_letter in seen:\n            seen[initial_letter].append(j)\n        else:\n            seen[initial_letter] = [j]\n\n    alliteration_annotations = []\n    # This part of the logic seems to run only once if the original condition was met.\n    # Assuming the goal is to find all alliterations in the line:\n    # Check if any letter appears more than once\n    if any(len(idx_list) &gt; 1 for idx_list in seen.values()):\n        for symbol, positions in seen.items():\n            if is_vowel(symbol):  # Only extract consonant alliterations\n                continue\n            if len(positions) &gt; 1:  # Need at least two words starting with this letter\n                # Group indices considering allowed intervening words\n                alliterating_groups = group_alliterating_indices(positions, words, allowed_intervening_words)\n\n                for group_indices in alliterating_groups:\n                    # group_alliterating_indices already ensures len(group_indices) &gt;= 2\n                    alliteration_annotations.append([words[p] for p in group_indices])\n\n    return alliteration_annotations if alliteration_annotations else None\n</code></pre>"},{"location":"api_alliteration/#poetry_analysis.alliteration.group_alliterating_indices","title":"<code>group_alliterating_indices(indices, all_words_in_line, stop_words)</code>","text":"<p>Groups indices of words that alliterate, allowing specified stop_words in between.</p> Source code in <code>src/poetry_analysis/alliteration.py</code> <pre><code>def group_alliterating_indices(indices: list, all_words_in_line: list, stop_words: list):\n    \"\"\"\n    Groups indices of words that alliterate, allowing specified stop_words in between.\n    \"\"\"\n    if not indices:\n        return []\n\n    result_groups = []\n    current_group_indices = [indices[0]]\n\n    for i in range(1, len(indices)):\n        prev_allit_idx = current_group_indices[-1]\n        current_potential_idx = indices[i]\n\n        can_extend_group = True\n        # Check words between prev_allit_idx and current_potential_idx\n        if current_potential_idx &gt; prev_allit_idx + 1:\n            for intervening_idx in range(prev_allit_idx + 1, current_potential_idx):\n                if (\n                    intervening_idx &gt;= len(all_words_in_line)\n                    or not all_words_in_line[intervening_idx]\n                    or all_words_in_line[intervening_idx].lower() not in stop_words\n                ):\n                    can_extend_group = False\n                    break\n\n        if can_extend_group:\n            current_group_indices.append(current_potential_idx)\n        else:\n            # Store group if it has at least 2 alliterating words\n            if len(current_group_indices) &gt;= 2:\n                result_groups.append(list(current_group_indices))  # Store a copy\n            current_group_indices = [current_potential_idx]\n\n    # Add the last formed group if it's valid\n    if len(current_group_indices) &gt;= 2:\n        result_groups.append(list(current_group_indices))\n\n    return result_groups\n</code></pre>"},{"location":"api_anaphora/","title":"Anaphora","text":""},{"location":"api_anaphora/#poetry_analysis.anaphora","title":"<code>poetry_analysis.anaphora</code>","text":"<p>Anaphora is the repetition of the same line-initial word or phrase in a verse, or across consecutive verses in a stanza.</p> <p>TODO: It can also refer to the repetition of a whole stanza-initial verse line in consecutive stanzas.</p> <p>NOTE: This has not been implemented yet. This anaphora detection process is based on the repetition of the first word in each line. We will continue with implementing a grading system for how effective the figure is in each poem.</p>"},{"location":"api_anaphora/#poetry_analysis.anaphora.count_initial_phrases","title":"<code>count_initial_phrases(text)</code>","text":"<p>Count the number of times string-initial phrases of different lengths occur in a string.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def count_initial_phrases(text: str) -&gt; Counter:\n    \"\"\"Count the number of times string-initial phrases of different lengths occur in a string.\"\"\"\n    phrase_counts = Counter()\n\n    lowercase = text.strip().lower()\n    normalized_text = utils.strip_punctuation(lowercase)\n    words = utils.tokenize(normalized_text)\n    n_words = len(words)\n\n    for n in range(1, n_words + 1):\n        if len(words) &gt;= n:\n            phrase = \" \".join(words[:n])\n            count = normalized_text.count(phrase)\n            if count &gt; 0:\n                phrase_counts[phrase] += count\n    return phrase_counts\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.detect_repeating_lines","title":"<code>detect_repeating_lines(text)</code>","text":"<p>Detect repeating lines in a poem.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def detect_repeating_lines(text: str) -&gt; list:\n    \"\"\"Detect repeating lines in a poem.\"\"\"\n    stanzas = utils.split_stanzas(text)\n    lines = [line.strip() for stanza in stanzas for line in stanza]\n\n    repeating_lines = {}\n    for idx, line in enumerate(lines):\n        if line in repeating_lines:\n            repeating_lines[line].append(idx)\n        else:\n            total = lines.count(line)\n            if total &gt; 1:\n                repeating_lines[line] = [idx]\n\n    return [(indeces, line) for line, indeces in repeating_lines.items()]\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.extract_anaphora","title":"<code>extract_anaphora(text)</code>","text":"<p>Extract line-initial word sequences that are repeated at least twice.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import json\n&gt;&gt;&gt; text = '''\n... Jeg ser paa den hvide himmel,\n... jeg ser paa de graablaa skyer,\n... jeg ser paa den blodige sol.\n...\n... Dette er altsaa verden.\n... Dette er altsaa klodernes hjem.\n...\n... En regndraabe!\n... '''\n&gt;&gt;&gt; result = extract_anaphora(text)\n&gt;&gt;&gt; print(json.dumps(result, indent=4))\n{\n    \"1-grams\": {\n        \"jeg\": 3,\n        \"dette\": 2\n    },\n    \"2-grams\": {\n        \"jeg ser\": 3,\n        \"dette er\": 2\n    },\n    \"3-grams\": {\n        \"jeg ser paa\": 3,\n        \"dette er altsaa\": 2\n    },\n    \"4-grams\": {\n        \"jeg ser paa den\": 2\n    }\n}\n</code></pre> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def extract_anaphora(text: str) -&gt; dict:\n    \"\"\"Extract line-initial word sequences that are repeated at least twice.\n\n    Examples:\n        &gt;&gt;&gt; import json\n        &gt;&gt;&gt; text = '''\n        ... Jeg ser paa den hvide himmel,\n        ... jeg ser paa de graablaa skyer,\n        ... jeg ser paa den blodige sol.\n        ...\n        ... Dette er altsaa verden.\n        ... Dette er altsaa klodernes hjem.\n        ...\n        ... En regndraabe!\n        ... '''\n        &gt;&gt;&gt; result = extract_anaphora(text)\n        &gt;&gt;&gt; print(json.dumps(result, indent=4))\n        {\n            \"1-grams\": {\n                \"jeg\": 3,\n                \"dette\": 2\n            },\n            \"2-grams\": {\n                \"jeg ser\": 3,\n                \"dette er\": 2\n            },\n            \"3-grams\": {\n                \"jeg ser paa\": 3,\n                \"dette er altsaa\": 2\n            },\n            \"4-grams\": {\n                \"jeg ser paa den\": 2\n            }\n        }\n    \"\"\"\n    lines = text.strip().lower().splitlines()\n    ngram_counts = defaultdict(lambda: defaultdict(int))\n\n    for line in lines:\n        text = utils.strip_punctuation(line)\n        words = text.split()\n        n_words = len(words)\n        for n in range(1, n_words + 1):\n            if len(words) &gt;= n:\n                ngram = \" \".join(words[:n])\n                ngram_counts[n][ngram] += 1\n\n    anaphora = {}\n    for n in range(1, 5):\n        ngram_type = f\"{n}-grams\"\n        ngrams = {ngram: count for ngram, count in ngram_counts[n].items() if count &gt; 1}\n        if ngrams:\n            anaphora[ngram_type] = ngrams\n    return anaphora\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.extract_line_anaphora","title":"<code>extract_line_anaphora(text)</code>","text":"<p>Extract line initial word sequences that are repeated at least twice on the same line.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def extract_line_anaphora(text: str) -&gt; list:\n    \"\"\"Extract line initial word sequences that are repeated at least twice on the same line.\"\"\"\n    anaphora = []\n    lines = text.strip().splitlines()\n    for i, line in enumerate(lines):\n        line_initial_phrases = count_initial_phrases(line)\n        phrase, count = find_longest_most_frequent_anaphora(line_initial_phrases)\n        if count &gt; 1:\n            annotation = {\"line_id\": i, \"phrase\": phrase, \"count\": count}\n            anaphora.append(annotation)\n    return anaphora\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.extract_poem_anaphora","title":"<code>extract_poem_anaphora(text)</code>","text":"<p>Extract line-initial word sequences that are repeated at least twice in each stanza.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def extract_poem_anaphora(text: str) -&gt; list:\n    \"\"\"Extract line-initial word sequences that are repeated at least twice in each stanza.\"\"\"\n    anaphora = []\n\n    stanzas = utils.split_stanzas(text)\n    for i, stanza in enumerate(stanzas):\n        stanza_anaphora = extract_stanza_anaphora(stanza)\n\n        for item in filter_anaphora(stanza_anaphora):\n            item[\"stanza_id\"] = i\n            anaphora.append(item)\n\n    return anaphora\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.extract_stanza_anaphora","title":"<code>extract_stanza_anaphora(stanza, n_words=1)</code>","text":"<p>Gather indeces for all lines that a line-initial word repeats across successively.</p> <p>Parameters:</p> Name Type Description Default <code>n_words</code> <code>int</code> <p>Number of words to expect in the anaphora, must be 1 or higher. If higher, a single word that is repeated more often than a phrase of n_words will be ignored in favour of the less frequent phrase.</p> <code>1</code> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def extract_stanza_anaphora(stanza: list[str], n_words: int = 1) -&gt; dict:\n    \"\"\"Gather indeces for all lines that a line-initial word repeats across successively.\n\n    Args:\n        n_words: Number of words to expect in the anaphora, must be 1 or higher.\n            If higher, a single word that is repeated more often than a phrase of\n            n_words will be ignored in favour of the less frequent phrase.\n    \"\"\"\n    stanza_anaphora = {}\n    empty_list = []\n    lines = [utils.normalize(line) if line else empty_list for line in stanza]\n    for line_index, words in enumerate(lines):\n        if not words:\n            continue\n\n        first_phrase = \" \".join(words[:n_words])\n        if line_index == 0:\n            stanza_anaphora[first_phrase] = [line_index]\n            continue\n\n        previous_line = lines[line_index - 1]\n        try:\n            previous_first_phrase = \" \".join(previous_line[:n_words])\n        except IndexError:\n            previous_first_phrase = None\n\n        if line_index &gt; 0 and previous_first_phrase == first_phrase:\n            stanza_anaphora[first_phrase].append(line_index)\n        else:\n            stanza_anaphora[first_phrase] = [line_index]\n\n    return stanza_anaphora\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.filter_anaphora","title":"<code>filter_anaphora(stanza_anaphora)</code>","text":"<p>Construct and yield an annotation dictionary only for stanzas where anaphora are immediately successive.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def filter_anaphora(stanza_anaphora: dict) -&gt; Generator:\n    \"\"\"Construct and yield an annotation dictionary\n    only for stanzas where anaphora are immediately successive.\"\"\"\n    for phrase, indeces in stanza_anaphora.items():\n        if len(indeces) &lt;= 1:\n            continue\n        if all(is_successive(indeces)):\n            annotation = {\n                \"line_id\": indeces,\n                \"phrase\": phrase,\n                \"count\": len(indeces),\n            }\n            yield annotation\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.find_longest_most_frequent_anaphora","title":"<code>find_longest_most_frequent_anaphora(phrases)</code>","text":"<p>Find the longest and most repeated word sequence in a counter.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def find_longest_most_frequent_anaphora(phrases: Counter) -&gt; tuple:\n    \"\"\"Find the longest and most repeated word sequence in a counter.\"\"\"\n    if phrases:\n        _, highest_count = phrases.most_common()[0]\n        top_phrases = [phrase for phrase, _ in phrases.most_common() if phrases[phrase] == highest_count]\n\n        longest_phrase = max(top_phrases, key=len)\n        longest_count = phrases[longest_phrase]\n\n        return longest_phrase, longest_count\n    return (None, 0)\n</code></pre>"},{"location":"api_anaphora/#poetry_analysis.anaphora.is_successive","title":"<code>is_successive(items)</code>","text":"<p>Assert whether all numbers in a list are monotonic and incremental.</p> Source code in <code>src/poetry_analysis/anaphora.py</code> <pre><code>def is_successive(items: list[int]) -&gt; list[bool]:\n    \"\"\"Assert whether all numbers in a list are monotonic and incremental.\"\"\"\n    return [items[i] == items[i - 1] + 1 for i, item in enumerate(items)][1:]\n</code></pre>"},{"location":"api_end_rhymes/","title":"End Rhymes","text":""},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection","title":"<code>poetry_analysis.rhyme_detection</code>","text":""},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.Verse","title":"<code>Verse</code>  <code>dataclass</code>","text":"Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>@dataclass\nclass Verse:\n    id_: str | int\n    rhyme_score: int = 0\n    rhyme_tag: str = \"\"\n    text: str = \"\"\n    transcription: str = \"\"\n    tokens: list | None = None\n    syllables: list | None = None\n    last_token: str | None = None\n    rhymes_with: str | int | None = None\n\n    @property\n    def dict(self) -&gt; dict:\n        \"\"\"Return the Verse object as a dictionary.\"\"\"\n        dictionary = self.__dict__\n        dictionary[\"verse_id\"] = self.id_\n        del dictionary[\"id_\"]\n        return dictionary\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.Verse.dict","title":"<code>dict</code>  <code>property</code>","text":"<p>Return the Verse object as a dictionary.</p>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.collate_rhyme_scheme","title":"<code>collate_rhyme_scheme(annotated_stanza)</code>","text":"<p>Join the rhyme tags rom each tagged verse to form a rhyme scheme.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def collate_rhyme_scheme(annotated_stanza: list) -&gt; str:\n    \"\"\"Join the rhyme tags rom each tagged verse to form a rhyme scheme.\"\"\"\n    return \"\".join(verse.rhyme_tag for verse in annotated_stanza)\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.find_last_stressed_syllable","title":"<code>find_last_stressed_syllable(syll)</code>","text":"<p>Find the last stressed syllable in a list of syllables.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def find_last_stressed_syllable(syll):\n    \"\"\"Find the last stressed syllable in a list of syllables.\"\"\"\n    n = len(syll)\n\n    for i in range(1, n + 1):\n        if re.search(r\"[123]\", syll[-i]):\n            return syll[-i:]\n    return syll[:]\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.find_last_word","title":"<code>find_last_word(tokens)</code>","text":"<p>Find the last word in a list of tokens.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def find_last_word(tokens: list[str]) -&gt; str:\n    \"\"\"Find the last word in a list of tokens.\"\"\"\n    for token in reversed(tokens):\n        if not utils.is_punctuation(token):\n            return token\n    return \"\"\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.find_nucleus","title":"<code>find_nucleus(word, orthographic=False)</code>","text":"<p>Check if a word has a valid syllable nucleus.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def find_nucleus(word: str, orthographic: bool = False) -&gt; re.Match | None:\n    \"\"\"Check if a word has a valid syllable nucleus.\"\"\"\n    valid_nuclei = get_valid_nuclei(orthographic=orthographic)\n    rgx = re.compile(rf\"({'|'.join(valid_nuclei)})\")\n    nucleus = rgx.search(word)\n    return nucleus\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.find_rhyming_line","title":"<code>find_rhyming_line(current, previous_lines, orthographic=False)</code>","text":"<p>Check if the current line rhymes with any of the previous lines.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def find_rhyming_line(current: Verse, previous_lines: list[Verse], orthographic: bool = False) -&gt; tuple:\n    \"\"\"Check if the current line rhymes with any of the previous lines.\"\"\"\n\n    for idx, previous in reversed(list(enumerate(previous_lines))):\n        if previous.last_token is None or current.last_token is None:\n            continue\n        rhyme_score = score_rhyme(previous.last_token, current.last_token, orthographic=orthographic)\n        if rhyme_score &gt; 0:\n            return idx, rhyme_score\n    return None, 0\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.get_stanzas_from_transcription","title":"<code>get_stanzas_from_transcription(transcription, orthographic=False)</code>","text":"<p>Parse a dict of transcribed verse lines and return a list of stanzas.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def get_stanzas_from_transcription(transcription: dict, orthographic: bool = False) -&gt; list:\n    \"\"\"Parse a dict of transcribed verse lines and return a list of stanzas.\"\"\"\n    line_ids = [x for x in transcription if x.startswith(\"line_\")]\n    n_lines = len(line_ids)\n    logging.debug(\"Number of lines in poem: %s\", n_lines)\n    poem = []\n    stanza = []\n    for line_n in line_ids:\n        verse = transcription.get(line_n)\n        if (verse is not None) and (len(verse) &gt; 0):\n            words, pron = zip(*verse, strict=False)\n            verseline = list(words if orthographic else pron)\n            stanza.append(verseline)\n        else:\n            if len(stanza) == 0:\n                continue\n            poem.append(stanza)\n            stanza = []\n    if len(poem) == 0 and len(stanza) &gt; 0:\n        poem.append(stanza)\n    return poem\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.get_valid_nuclei","title":"<code>get_valid_nuclei(orthographic=False)</code>","text":"<p>Return the list of valid syllable nuclei with either graphemes or Nofabet phonemes.</p> <p>Parameters:</p> Name Type Description Default <code>orthographic</code> <code>bool</code> <p>If True, return graphemes</p> <code>False</code> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def get_valid_nuclei(orthographic: bool = False) -&gt; list:\n    \"\"\"Return the list of valid syllable nuclei with either graphemes or Nofabet phonemes.\n\n    Args:\n        orthographic: If True, return graphemes\n    \"\"\"\n    return utils.VALID_NUCLEI if orthographic else phonetic_inventory.PHONES_NOFABET[\"nuclei\"]\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.is_nucleus","title":"<code>is_nucleus(symbol, orthographic=False)</code>","text":"<p>Check if a phoneme or a letter is a valid syllable nucleus.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def is_nucleus(symbol: str, orthographic: bool = False) -&gt; bool:\n    \"\"\"Check if a phoneme or a letter is a valid syllable nucleus.\"\"\"\n    valid_nuclei = get_valid_nuclei(orthographic=orthographic)\n    return strip_stress(symbol) in valid_nuclei\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.is_schwa","title":"<code>is_schwa(string)</code>","text":"<p>Check if a string object is the schwa sound.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def is_schwa(string: str) -&gt; bool:\n    \"\"\"Check if a string object is the schwa sound.\"\"\"\n    string = string.strip()\n    return (string == \"e\") or (string == \"AX\") or (string == \"AX0\")\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.is_stressed","title":"<code>is_stressed(syllable)</code>","text":"<p>Check if a syllable is stressed by searching for stress markers.</p> Stress markers <ul> <li><code>0</code>: Vowel/syllable nucleus without stress</li> <li><code>1</code>: Primary stress with toneme 1</li> <li><code>2</code>: Primary stress with toneme 2</li> <li><code>3</code>: Secondary stress</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_stressed(\"a1\")\nTrue\n&gt;&gt;&gt; is_stressed(\"a0\")\nFalse\n&gt;&gt;&gt; is_stressed([\"a\", \"1\"])\nTrue\n&gt;&gt;&gt; is_stressed([\"a\", \"0\"])\nFalse\n</code></pre> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def is_stressed(syllable: str | list) -&gt; bool:\n    \"\"\"Check if a syllable is stressed by searching for stress markers.\n\n    Stress markers:\n        - `0`: Vowel/syllable nucleus without stress\n        - `1`: Primary stress with toneme 1\n        - `2`: Primary stress with toneme 2\n        - `3`: Secondary stress\n\n    Examples:\n        &gt;&gt;&gt; is_stressed(\"a1\")\n        True\n        &gt;&gt;&gt; is_stressed(\"a0\")\n        False\n        &gt;&gt;&gt; is_stressed([\"a\", \"1\"])\n        True\n        &gt;&gt;&gt; is_stressed([\"a\", \"0\"])\n        False\n    \"\"\"\n    if isinstance(syllable, list):\n        syllable = \" \".join(syllable)\n    result = re.search(r\"[123]\", syllable)\n    return bool(result)\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.longest_common_substring","title":"<code>longest_common_substring(string1, string2)</code>","text":"<p>Find the longest common substring between two strings.</p> <p>Implementation based on the pseudocode from: https://en.wikipedia.org/wiki/Longest_common_substring#Dynamic_programming</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def longest_common_substring(string1: str, string2: str) -&gt; str:\n    \"\"\"Find the longest common substring between two strings.\n\n    Implementation based on the pseudocode from:\n    https://en.wikipedia.org/wiki/Longest_common_substring#Dynamic_programming\n    \"\"\"\n    m = len(string1)\n    n = len(string2)\n    L = np.zeros((m + 1, n + 1))\n    z = 0\n    result = \"\"\n\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if string1[i - 1] == string2[j - 1]:\n                L[i][j] = L[i - 1][j - 1] + 1\n                if L[i][j] &gt; z:\n                    z = L[i][j]\n                    result = string1[(i - int(z)) : i]\n            else:\n                L[i][j] = 0\n    return result\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.main","title":"<code>main()</code>","text":"<p>Main function to run the rhyme detection script.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def main():\n    \"\"\"Main function to run the rhyme detection script.\"\"\"\n    import argparse\n    from datetime import datetime\n\n    parser = argparse.ArgumentParser(description=\"Tag rhyme schemes in a poem.\")\n    parser.add_argument(\n        \"-f\",\n        \"--poemfile\",\n        type=Path,\n        help=\"Path to a json file with phonemic transcriptions.\",\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--doctest\",\n        action=\"store_true\",\n        help=\"Run doctests in the module.\",\n    )\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Set logging level to debug.\")\n    args = parser.parse_args()\n\n    if args.verbose:\n        today = datetime.today().date()\n        logging_file = f\"{__file__.split('.')[0]}_{today}.log\"\n        logging.basicConfig(level=logging.DEBUG, filename=logging_file, filemode=\"a\")\n\n    if args.poemfile:\n        tag_poem_file(args.poemfile, write_to_file=True)\n\n    if args.doctest:\n        import doctest\n\n        logging.debug(\"Running doctests...\")\n        doctest.testmod(verbose=True)\n        logging.info(\"Doctests passed.\")\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.remove_syllable_onset","title":"<code>remove_syllable_onset(syllable)</code>","text":"<p>Split a syllable nucleus and coda from the onset to find the rhyming part of the syllable.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def remove_syllable_onset(syllable: list) -&gt; list | None:\n    \"\"\"Split a syllable nucleus and coda from the onset to find the rhyming part of the syllable.\"\"\"\n    for idx, phone in enumerate(syllable):\n        if is_nucleus(phone):\n            return syllable[idx:]\n    logging.debug(\"No nucleus found in %s\", syllable)\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.score_rhyme","title":"<code>score_rhyme(sequence1, sequence2, orthographic=False)</code>","text":"<p>Check if two words rhyme and return a rhyming score.</p> <p>Returns:</p> Type Description <code>float</code> <p><code>1.0</code>:    Only the syllable nucleus + coda (=rhyme) match # perfect or proper rhyme</p> <code>float</code> <p><code>0.5</code>:    N\u00d8DRIM or lame rhyme. One of the words is fully contained in the other, e.g. 'tusenfryd' / 'fryd'</p> <code>float</code> <p><code>0.0</code>:    No match</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def score_rhyme(sequence1: str, sequence2: str, orthographic: bool = False) -&gt; float:\n    \"\"\"Check if two words rhyme and return a rhyming score.\n\n    Returns:\n        `1.0`:    Only the syllable nucleus + coda (=rhyme) match # perfect or proper rhyme\n        `0.5`:    N\u00d8DRIM or lame rhyme. One of the words is fully contained in the other, e.g. 'tusenfryd' / 'fryd'\n        `0.0`:    No match\n    \"\"\"\n\n    substring = shared_ending_substring(sequence1, sequence2)\n\n    if not substring:\n        logging.debug(\"No shared ending substring found in %s and %s\", sequence1, sequence2)\n        return 0\n\n    nucleus = find_nucleus(substring, orthographic=orthographic)\n\n    if not nucleus:\n        logging.debug(\"no nucleus found in %s\", substring)\n        return 0\n    if utils.is_grammatical_suffix(substring):\n        logging.debug(\"only the grammatical suffixes match: %s\", substring)\n        # e.g. \"arbeidet\" / \"skrevet\"\n        return 0\n    if utils.is_grammatical_suffix(substring[nucleus.start() :]):\n        logging.debug(\"the rhyming part is a grammatical suffix: %s\", substring[nucleus.start() :])\n        # e.g. \"blomster\" / \"fester\"\n        return 0\n    if is_schwa(substring):\n        logging.debug(\n            \"the rhyming part is scwha (%s) and the words share no other vowels: %s\",\n            substring,\n            (sequence1, sequence2),\n        )\n        return 0\n\n    if not sequence1.endswith(substring) or not sequence2.endswith(substring):\n        # not an end rhyme\n        logging.debug(\"not an end rhyme: %s and %s\", sequence1, sequence2)\n        return 0\n    if substring in (sequence1, sequence2):\n        # one of the words is fully contained in the other\n        logging.debug(\"N\u00f8drim: %s and %s\", sequence1, sequence2)\n        return 0.5\n\n    if nucleus and (sequence1 != sequence2):\n        logging.debug(\"Proper rhyme: %s and %s\", sequence1, sequence2)\n        return 1\n    # otherwise, assume that the words do not rhyme\n    logging.debug(\"No condition met for a rhyme: %s and %s\", sequence1, sequence2)\n    return 0\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.shared_ending_substring","title":"<code>shared_ending_substring(string1, string2)</code>","text":"<p>Find the shared substring at the end of two strings.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def shared_ending_substring(string1: str, string2: str) -&gt; str:\n    \"\"\"Find the shared substring at the end of two strings.\"\"\"\n    min_length = min(len(string1), len(string2))\n\n    for i in range(1, min_length + 1):\n        if string1[-i] != string2[-i]:\n            final_substring = string1[-i + 1 :] if i &gt; 1 else \"\"\n            return final_substring\n    return string1[-min_length:] if min_length &gt; 0 else \"\"\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.strip_stress","title":"<code>strip_stress(phoneme)</code>","text":"<p>Strip the stress marker from a phoneme.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def strip_stress(phoneme: str) -&gt; str:\n    \"\"\"Strip the stress marker from a phoneme.\"\"\"\n    return phoneme.strip(\"0123\")\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.tag_poem_file","title":"<code>tag_poem_file(poem_file, write_to_file=False)</code>","text":"<p>Annotate rhyming schemes in a poem from a file.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def tag_poem_file(poem_file: str, write_to_file: bool = False) -&gt; list:\n    \"\"\"Annotate rhyming schemes in a poem from a file.\"\"\"\n    # Assume that the stanzas are independent of each other\n    # and that the rhyme scheme is unique to each stanza\n\n    filepath = Path(poem_file)\n    file_content = filepath.read_text(encoding=\"utf-8\")\n    if filepath.suffix == \".json\":\n        poem = json.loads(file_content)\n        poem_id = poem.get(\"text_id\")\n        orthographic = False\n        stanzas = get_stanzas_from_transcription(poem, orthographic=orthographic)\n\n    elif filepath.suffix == \".txt\":\n        poem_id = filepath.stem.split(\"_\")[0]\n        stanzas = utils.split_stanzas(file_content)\n        orthographic = True\n\n    logging.debug(\"Tagging poem: %s\", poem_id)\n\n    file_annotations = list(tag_stanzas(stanzas, orthographic=orthographic))\n\n    if write_to_file:\n        outputfile = filepath.parent / f\"{filepath.stem}_rhyme_scheme.json\"\n        with outputfile.open(\"w\") as f:\n            f.write(json.dumps(file_annotations, ensure_ascii=False, indent=4))\n\n        logging.debug(\"Saved rhyme scheme annotations for poem %s to \\n\\t%s\", poem_id, outputfile)\n    return file_annotations\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.tag_rhyming_verses","title":"<code>tag_rhyming_verses(verses, orthographic=False)</code>","text":"<p>Annotate end rhyme patterns in a poem stanza.</p> <p>Parameters:</p> Name Type Description Default <code>verses</code> <code>list</code> <p>list of verselines with words</p> required <code>orthographic</code> <code>bool</code> <p>if True, the words strings are orthographic, otherwise assume phonemic nofabet transcriptions</p> <code>False</code> <p>Return:     list of annotated verses with rhyme scores and rhyme tags</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def tag_rhyming_verses(verses: list, orthographic: bool = False) -&gt; list:\n    \"\"\"Annotate end rhyme patterns in a poem stanza.\n\n    Args:\n        verses: list of verselines with words\n        orthographic: if True, the words strings are orthographic,\n            otherwise assume phonemic nofabet transcriptions\n    Return:\n        list of annotated verses with rhyme scores and rhyme tags\n    \"\"\"\n    alphabet = iter(string.ascii_letters)\n\n    processed = []  # needs to be a list!\n    for idx, verseline in enumerate(verses):\n        if not verseline:\n            continue\n\n        if orthographic:\n            tokens = utils.normalize(verseline)\n            last_word = find_last_word(tokens)\n            if not last_word:\n                logging.debug(\"No tokens found in %s\", verseline)\n                continue\n            current_verse = Verse(\n                id_=idx,\n                text=verseline,\n                tokens=tokens,\n                last_token=last_word.casefold(),\n            )\n        else:\n            syllables = utils.convert_to_syllables(verseline, ipa=False)\n            last_syllable = \" \".join(find_last_stressed_syllable(syllables))\n\n            current_verse = Verse(\n                id_=idx,\n                transcription=\"\\t\".join(verseline),\n                tokens=verseline,\n                syllables=syllables,\n                last_token=re.sub(r\"[0123]\", \"\", last_syllable),\n            )\n\n        rhyming_idx, rhyme_score = find_rhyming_line(current_verse, processed, orthographic=orthographic)\n\n        if rhyming_idx is not None and rhyme_score &gt; 0:\n            rhyming_verse = processed[rhyming_idx]\n            current_verse.rhyme_tag = rhyming_verse.rhyme_tag\n            current_verse.rhyme_score = rhyme_score\n            current_verse.rhymes_with = rhyming_verse.id_\n\n        else:\n            try:\n                current_verse.rhyme_tag = next(alphabet)\n            except StopIteration:\n                logging.info(\"Ran out of rhyme tags at %s! Initialising new alphabet.\", idx)\n                alphabet = iter(string.ascii_letters)\n                current_verse.rhyme_tag = next(alphabet)\n\n        processed.append(current_verse)\n    return processed\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.tag_stanzas","title":"<code>tag_stanzas(stanzas, orthographic=False)</code>","text":"<p>Iterate over stanzas and tag verses with a rhyme scheme.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def tag_stanzas(stanzas: list, orthographic: bool = False) -&gt; Generator:\n    \"\"\"Iterate over stanzas and tag verses with a rhyme scheme.\"\"\"\n    for idx, stanza in enumerate(stanzas):\n        tagged = tag_rhyming_verses(stanza, orthographic=orthographic)\n        rhyme_scheme = collate_rhyme_scheme(tagged)\n\n        yield {\n            \"stanza_id\": idx,\n            \"rhyme_scheme\": rhyme_scheme,\n            \"verses\": [verse.dict for verse in tagged],\n        }\n</code></pre>"},{"location":"api_end_rhymes/#poetry_analysis.rhyme_detection.tag_text","title":"<code>tag_text(text)</code>","text":"<p>Annotate rhyming schemes in a text where stanzas are separated by two empty lines.</p> Source code in <code>src/poetry_analysis/rhyme_detection.py</code> <pre><code>def tag_text(text: str) -&gt; Generator:\n    \"\"\"Annotate rhyming schemes in a text where stanzas are separated by two empty lines.\"\"\"\n    stanzas = utils.split_stanzas(text)\n    file_annotations = tag_stanzas(stanzas, orthographic=True)\n    return file_annotations\n</code></pre>"},{"location":"api_lyrical_subject/","title":"Lyrical subject","text":""},{"location":"api_lyrical_subject/#poetry_analysis.lyrical_subject","title":"<code>poetry_analysis.lyrical_subject</code>","text":""},{"location":"api_lyrical_subject/#poetry_analysis.lyrical_subject.add_metadata","title":"<code>add_metadata(poem, lyric_features)</code>","text":"<p>Add metadata from the poem to the annotations.</p> Source code in <code>src/poetry_analysis/lyrical_subject.py</code> <pre><code>def add_metadata(poem, lyric_features):\n    \"\"\"Add metadata from the poem to the annotations.\"\"\"\n    lyric_features[\"ID\"] = int(poem.get(\"ID\"))\n    lyric_features[\"URN\"] = poem.get(\"URN\")\n    lyric_features[\"Tittel p\u00e5 dikt\"] = poem.get(\"Tittel p\u00e5 dikt\")\n    return lyric_features\n</code></pre>"},{"location":"api_lyrical_subject/#poetry_analysis.lyrical_subject.detect_lyrical_subject","title":"<code>detect_lyrical_subject(poem_text)</code>","text":"<p>Map the presence of certain words denoting a lyrical subject in a poem to categorical labels.</p> Source code in <code>src/poetry_analysis/lyrical_subject.py</code> <pre><code>def detect_lyrical_subject(poem_text: str) -&gt; dict:\n    \"\"\"Map the presence of certain words denoting a lyrical subject in a poem to categorical labels.\"\"\"\n    lyrical_subject = {}\n    for label, words in WORDBAGS.items():\n        regx_pattern = \"|\".join(words)\n        matches = re.findall(regx_pattern, poem_text.lower())\n        is_present = bool(any(matches))\n        lyrical_subject[label] = is_present\n    return lyrical_subject\n</code></pre>"},{"location":"api_lyrical_subject/#poetry_analysis.lyrical_subject.process_poems","title":"<code>process_poems(poems, text_field='textV3')</code>","text":"<p>Annotate whether or not the lyrical subject is a feature in a list of poems.</p> Source code in <code>src/poetry_analysis/lyrical_subject.py</code> <pre><code>def process_poems(poems, text_field=\"textV3\"):\n    \"\"\"Annotate whether or not the lyrical subject is a feature in a list of poems.\"\"\"\n\n    for poem in poems:\n        poem_text = poem.get(text_field)\n        lyric_features = detect_lyrical_subject(poem_text)\n        yield add_metadata(poem, lyric_features)\n</code></pre>"},{"location":"api_utils/","title":"Utility functions","text":""},{"location":"api_utils/#poetry_analysis.utils","title":"<code>poetry_analysis.utils</code>","text":""},{"location":"api_utils/#poetry_analysis.utils.convert_to_syllables","title":"<code>convert_to_syllables(phonemes, ipa=False)</code>","text":"<p>Turn a sequence of phonemes into syllable groups.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def convert_to_syllables(phonemes: str | list, ipa: bool = False) -&gt; list:\n    \"\"\"Turn a sequence of phonemes into syllable groups.\"\"\"\n    transcription = phonemes if isinstance(phonemes, str) else \" \".join(phonemes)\n    if ipa:\n        ipa_str = nofabet_to_ipa(transcription)\n        syllables = ipa_str.split(\".\")\n    else:\n        nofabet_syllables = nofabet_to_syllables(transcription)\n        syllables = [\" \".join(syll) for syll in nofabet_syllables]\n    return syllables\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.endswith","title":"<code>endswith(sequence, suffix)</code>","text":"<p>Check if a sequence ends with a given suffix.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def endswith(sequence: str | list[str], suffix: str) -&gt; bool:\n    \"\"\"Check if a sequence ends with a given suffix.\"\"\"\n    if isinstance(sequence, str):\n        return sequence.endswith(suffix)\n    elif isinstance(sequence, list):\n        last_element = sequence.copy().pop()\n        if isinstance(last_element, str):\n            return last_element.endswith(suffix)\n        return False\n    return False\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.gather_stanza_annotations","title":"<code>gather_stanza_annotations(func)</code>","text":"<p>Decorator to apply a function to each stanza in a text.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def gather_stanza_annotations(func) -&gt; Callable:\n    \"\"\"Decorator to apply a function to each stanza in a text.\"\"\"\n\n    def wrapper(text: str) -&gt; dict:\n        stanzas = split_stanzas(text)\n        stanza_annotations = {}\n        for i, stanza in enumerate(stanzas, 1):\n            stanza_text = \"\\n\".join(stanza)\n            stanza_annotations[f\"stanza_{i}\"] = func(stanza_text)\n        return stanza_annotations\n\n    return wrapper\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.group_consecutive_numbers","title":"<code>group_consecutive_numbers(nums)</code>","text":"<p>Group consecutive numbers into sublists.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list_of_numbers = [1, 2, 3, 5, 6, 8, 9, 10]\n&gt;&gt;&gt; result = group_consecutive_numbers(list_of_numbers)\n&gt;&gt;&gt; print(result)\n[[1, 2, 3], [5, 6], [8, 9, 10]]\n</code></pre> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def group_consecutive_numbers(nums: list[int]) -&gt; list[list[int]]:\n    \"\"\"Group consecutive numbers into sublists.\n\n    Examples:\n        &gt;&gt;&gt; list_of_numbers = [1, 2, 3, 5, 6, 8, 9, 10]\n        &gt;&gt;&gt; result = group_consecutive_numbers(list_of_numbers)\n        &gt;&gt;&gt; print(result)\n        [[1, 2, 3], [5, 6], [8, 9, 10]]\n    \"\"\"\n    if not nums:\n        return []\n\n    nums = sorted(nums)\n    result = []\n    current_group = [nums[0]]\n\n    for i in range(1, len(nums)):\n        if nums[i] == nums[i - 1] + 1:\n            current_group.append(nums[i])\n        else:\n            result.append(current_group)\n            current_group = [nums[i]]\n\n    result.append(current_group)\n    return result\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.is_punctuation","title":"<code>is_punctuation(char)</code>","text":"<p>Check if a character is a punctuation mark.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def is_punctuation(char: str) -&gt; bool:\n    \"\"\"Check if a character is a punctuation mark.\"\"\"\n    return char in PUNCTUATION_MARKS\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.is_valid_onset","title":"<code>is_valid_onset(phonelist)</code>","text":"<p>WORK IN PROGRESS Check if a sequence of characters forms a valid onset in Norwegian orthography.</p> <p>Parameters:</p> Name Type Description Default <code>phonelist</code> <code>str</code> <p>A string representing the onset (e.g., \"bl\", \"tr\").</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the onset is valid, False otherwise.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def is_valid_onset(phonelist: str) -&gt; bool:\n    \"\"\"\n    WORK IN PROGRESS\n    Check if a sequence of characters forms a valid onset in Norwegian orthography.\n\n    Args:\n        phonelist (str): A string representing the onset (e.g., \"bl\", \"tr\").\n\n    Returns:\n        bool: True if the onset is valid, False otherwise.\n    \"\"\"\n    # Define valid single consonants and consonant clusters for Norwegian\n    valid_single_consonants = set(\"bcdfghjklmnpqrstvwxyz\")\n    valid_clusters = {\n        \"bj\",\n        \"bl\",\n        \"br\",\n        \"dr\",\n        \"dj\",\n        \"fl\",\n        \"fj\",\n        \"fr\",\n        \"gl\",\n        \"gr\",\n        \"gj\",\n        \"kj\",\n        \"kl\",\n        \"kr\",\n        \"kn\",\n        \"kv\",\n        \"pl\",\n        \"pj\",\n        \"pr\",\n        \"mj\",\n        \"nj\",\n        \"sj\",\n        \"sl\",\n        \"sm\",\n        \"sn\",\n        \"sp\",\n        \"st\",\n        \"sv\",\n        \"tr\",\n        \"tj\",\n        \"tl\",\n        \"vr\",\n        \"sk\",\n        \"skr\",\n        \"spr\",\n        \"str\",\n        \"skj\",\n        \"gn\",\n        \"hv\",\n    }\n\n    if len(phonelist) == 1 and phonelist in valid_single_consonants:\n        return True\n\n    return phonelist in valid_clusters\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.make_comparable_string","title":"<code>make_comparable_string(item)</code>","text":"<p>Convert a list of strings into a single comparable string.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def make_comparable_string(item: list | str) -&gt; str:\n    \"\"\"Convert a list of strings into a single comparable string.\"\"\"\n    string = \" \".join(item) if isinstance(item, list) else str(item)\n    string = strip_punctuation(string)\n    string = re.sub(r\"[0123]\", \"\", string)  # remove stress markers\n    return string.casefold()\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.normalize","title":"<code>normalize(text)</code>","text":"<p>Lowercase, remove punctuation and tokenize a string of text.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def normalize(text: str) -&gt; list[str]:\n    \"\"\"Lowercase, remove punctuation and tokenize a string of text.\"\"\"\n    lowercase = text.strip().lower()\n    alpanumeric_only = strip_punctuation(lowercase)\n    words = tokenize(alpanumeric_only)\n    return words\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.split_orthographic_text_into_syllables","title":"<code>split_orthographic_text_into_syllables(words)</code>","text":"<p>WORK IN PROGRESS Split orthographic text into syllables using basic rules. This is a simplified implementation and may not handle all edge cases.</p> <p>Parameters:</p> Name Type Description Default <code>words</code> <code>list of str</code> <p>A list of orthographic words, already tokenized</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of syllables for each word in the text.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def split_orthographic_text_into_syllables(words: list[str]) -&gt; list:\n    \"\"\"\n    WORK IN PROGRESS\n    Split orthographic text into syllables using basic rules.\n    This is a simplified implementation and may not handle all edge cases.\n\n    Args:\n        words (list of str): A list of orthographic words, already tokenized\n\n    Returns:\n        list: A list of syllables for each word in the text.\n    \"\"\"\n    syllables = []\n\n    for word in words:\n        word_syllables = []\n        current_syllable = \"\"\n\n        for i, char in enumerate(word):\n            current_syllable += char\n\n            # Check if the character is a vowel\n            if char in VALID_NUCLEI:\n                # Check if the next character could be part of the same nucleus\n                is_not_last = i + 1 &lt; len(word)\n                if is_not_last and word[i + 1] in VALID_NUCLEI:\n                    continue\n\n                # Check if the next character could be part of a valid onset\n                if is_not_last and word[i + 1] not in VALID_NUCLEI:\n                    consonant_cluster = char + word[i + 1]\n                    if len(consonant_cluster) &gt; 1 and is_valid_onset(consonant_cluster):\n                        continue\n\n                # Otherwise, split the syllable\n                word_syllables.append(current_syllable)\n                current_syllable = \"\"\n\n        # Add any remaining characters as a syllable\n        if current_syllable:\n            word_syllables.append(current_syllable)\n\n        syllables.append(word_syllables)\n\n    return syllables\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.split_paragraphs","title":"<code>split_paragraphs(text)</code>","text":"<p>Split a text into paragraphs and paragraphs into lines.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def split_paragraphs(text: str) -&gt; list:\n    \"\"\"Split a text into paragraphs and paragraphs into lines.\"\"\"\n    return [\n        [line.rstrip() for line in paragraph.rstrip().splitlines()]\n        for paragraph in re.split(\"\\n{2,}\", text)\n        if paragraph\n    ]\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.split_stanzas","title":"<code>split_stanzas(text)</code>","text":"<p>Split a poem into stanzas and stanzas into verses.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def split_stanzas(text: str) -&gt; list:\n    \"\"\"Split a poem into stanzas and stanzas into verses.\"\"\"\n    return [[verse.rstrip() for verse in stanza.rstrip().splitlines()] for stanza in re.split(\"\\n{2,}\", text) if stanza]\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.strip_punctuation","title":"<code>strip_punctuation(string)</code>","text":"<p>Remove punctuation from a string</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def strip_punctuation(string: str) -&gt; str:\n    \"\"\"Remove punctuation from a string\"\"\"\n    alphanumstr = \"\"\n    for char in string:\n        if not is_punctuation(char):\n            alphanumstr += char\n    return strip_redundant_whitespace(alphanumstr)\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.strip_redundant_whitespace","title":"<code>strip_redundant_whitespace(text)</code>","text":"<p>Strip redundant whitespace and reduce it to a single space.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def strip_redundant_whitespace(text: str) -&gt; str:\n    \"\"\"Strip redundant whitespace and reduce it to a single space.\"\"\"\n    return re.sub(r\"\\s+\", \" \", text).strip()\n</code></pre>"},{"location":"api_utils/#poetry_analysis.utils.syllabify","title":"<code>syllabify(transcription)</code>","text":"<p>Flatten list of syllables from a list of transcribed words.</p> Source code in <code>src/poetry_analysis/utils.py</code> <pre><code>def syllabify(transcription: list[list]) -&gt; list:\n    \"\"\"Flatten list of syllables from a list of transcribed words.\"\"\"\n    syllables = [\n        syll  # if syll is not None else \"NONE\"\n        for word, pron in transcription\n        for syll in convert_to_syllables(pron, ipa=False)\n    ]\n    return syllables\n</code></pre>"},{"location":"demo/","title":"Kodeveiledning","text":"In\u00a0[19]: Copied! <pre>text = \"\"\"At jeg, at jeg har kj\u00e6rligheden m\u00f8dt!\nDet er, som alt, som alt paany er f\u00f8dt!\nEt under er der i mit liv nu skeet,\nEt under, kj\u00e6rligheden, har jeg seet!\n\"\"\"\n\ntextlines = text.splitlines()\n</pre> text = \"\"\"At jeg, at jeg har kj\u00e6rligheden m\u00f8dt! Det er, som alt, som alt paany er f\u00f8dt! Et under er der i mit liv nu skeet, Et under, kj\u00e6rligheden, har jeg seet! \"\"\"  textlines = text.splitlines() In\u00a0[20]: Copied! <pre>from poetry_analysis.rhyme_detection import tag_rhyming_verses\n\nend_rhymes = tag_rhyming_verses(textlines, orthographic=True)\n\nend_rhymes\n</pre> from poetry_analysis.rhyme_detection import tag_rhyming_verses  end_rhymes = tag_rhyming_verses(textlines, orthographic=True)  end_rhymes Out[20]: <pre>[Verse(id_=0, rhyme_score=0, rhyme_tag='a', text='At jeg, at jeg har kj\u00e6rligheden m\u00f8dt!', transcription='', tokens=['at', 'jeg', 'at', 'jeg', 'har', 'kj\u00e6rligheden', 'm\u00f8dt'], syllables=None, last_token='m\u00f8dt', rhymes_with=None),\n Verse(id_=1, rhyme_score=1, rhyme_tag='a', text='Det er, som alt, som alt paany er f\u00f8dt!', transcription='', tokens=['det', 'er', 'som', 'alt', 'som', 'alt', 'paany', 'er', 'f\u00f8dt'], syllables=None, last_token='f\u00f8dt', rhymes_with=0),\n Verse(id_=2, rhyme_score=0, rhyme_tag='b', text='Et under er der i mit liv nu skeet,', transcription='', tokens=['et', 'under', 'er', 'der', 'i', 'mit', 'liv', 'nu', 'skeet'], syllables=None, last_token='skeet', rhymes_with=None),\n Verse(id_=3, rhyme_score=1, rhyme_tag='b', text='Et under, kj\u00e6rligheden, har jeg seet!', transcription='', tokens=['et', 'under', 'kj\u00e6rligheden', 'har', 'jeg', 'seet'], syllables=None, last_token='seet', rhymes_with=2)]</pre> <p>Dersom tekstdata ligger i en <code>.txt</code>-fil, kan vi hoppe over linjesegmenteringen, og bruke <code>tag_poem_file()</code>. Funksjonen b\u00e5de returnerer og skriver utdata til en <code>.json</code>-fil n\u00e5r vi skrur p\u00e5  <code>write_to_file</code>-flagget.</p> <p>OBS: Funksjonen antar at teksten i filen har to tomme linjer mellom hver strofe, dvs. tre  linjeskift etter siste vers i en strofe: <code>\"\\n\\n\\n\"</code></p> In\u00a0[21]: Copied! <pre>from pathlib import Path\n\nfrom poetry_analysis.rhyme_detection import tag_poem_file\n\npoem_file = \"./example_poem.txt\"\nPath(poem_file).write_text(text)\n\nresult = tag_poem_file(poem_file, write_to_file=True)\n\nresult[0]\n</pre> from pathlib import Path  from poetry_analysis.rhyme_detection import tag_poem_file  poem_file = \"./example_poem.txt\" Path(poem_file).write_text(text)  result = tag_poem_file(poem_file, write_to_file=True)  result[0] Out[21]: <pre>{'stanza_id': 0,\n 'rhyme_scheme': 'aabb',\n 'verses': [{'rhyme_score': 0,\n   'rhyme_tag': 'a',\n   'text': 'At jeg, at jeg har kj\u00e6rligheden m\u00f8dt!',\n   'transcription': '',\n   'tokens': ['at', 'jeg', 'at', 'jeg', 'har', 'kj\u00e6rligheden', 'm\u00f8dt'],\n   'syllables': None,\n   'last_token': 'm\u00f8dt',\n   'rhymes_with': None,\n   'verse_id': 0},\n  {'rhyme_score': 1,\n   'rhyme_tag': 'a',\n   'text': 'Det er, som alt, som alt paany er f\u00f8dt!',\n   'transcription': '',\n   'tokens': ['det', 'er', 'som', 'alt', 'som', 'alt', 'paany', 'er', 'f\u00f8dt'],\n   'syllables': None,\n   'last_token': 'f\u00f8dt',\n   'rhymes_with': 0,\n   'verse_id': 1},\n  {'rhyme_score': 0,\n   'rhyme_tag': 'b',\n   'text': 'Et under er der i mit liv nu skeet,',\n   'transcription': '',\n   'tokens': ['et', 'under', 'er', 'der', 'i', 'mit', 'liv', 'nu', 'skeet'],\n   'syllables': None,\n   'last_token': 'skeet',\n   'rhymes_with': None,\n   'verse_id': 2},\n  {'rhyme_score': 1,\n   'rhyme_tag': 'b',\n   'text': 'Et under, kj\u00e6rligheden, har jeg seet!',\n   'transcription': '',\n   'tokens': ['et', 'under', 'kj\u00e6rligheden', 'har', 'jeg', 'seet'],\n   'syllables': None,\n   'last_token': 'seet',\n   'rhymes_with': 2,\n   'verse_id': 3}]}</pre> In\u00a0[22]: Copied! <pre>from poetry_analysis.anaphora import extract_anaphora\n\nextract_anaphora(text)\n</pre> from poetry_analysis.anaphora import extract_anaphora  extract_anaphora(text) Out[22]: <pre>{'1-grams': {'et': 2}, '2-grams': {'et under': 2}}</pre> <p>Funksjonen <code>extract_line_anaphora</code> henter ut fraser som gjentar seg p\u00e5 samme linje</p> In\u00a0[23]: Copied! <pre>from poetry_analysis.anaphora import extract_line_anaphora\n\nextract_line_anaphora(text)\n</pre> from poetry_analysis.anaphora import extract_line_anaphora  extract_line_anaphora(text) Out[23]: <pre>[{'line_id': 0, 'phrase': 'at jeg', 'count': 2},\n {'line_id': 2, 'phrase': 'et', 'count': 2},\n {'line_id': 3, 'phrase': 'et', 'count': 2}]</pre> In\u00a0[24]: Copied! <pre>from poetry_analysis.alliteration import count_alliterations, fetch_alliteration_symbol, find_line_alliterations\n\ntext = \"\"\"Stjerneklare Septembernat \nSees Sirius, \nSydhimlens smukkeste \nStjerne, \nSolens skj\u00f8nneste S\u00f8ster, \nSv\u00e6ve saa stille, \nStraale saa smukt, \nSkue s\u00f8rgmodigt \nSl\u00e6gternes Strid. \nSine samlede Syner \nSender Stjernen Sirius \nSine store Sl\u00e6gtninge: \nSolen, Skorpionen, \nStolte, sv\u00f8mmende Svane, \nSydkorset, Saturn, \nSom straalende Stjerneskud. \nSirius ser saameget!\nSer Sagas skyh\u00f8ie S\u00e6de,\n\u2012 Store Skagast\u00f8lstind \u2012\nSom sydfor Sneh\u00e6tten staar.\"\"\"\n\nresult = find_line_alliterations(text)\nalliteration_count = count_alliterations(result)\nsymbol = fetch_alliteration_symbol(result)\n\nprint(f\"Fant {alliteration_count} ord som starter p\u00e5 '{symbol}': \")\nprint(result)\n</pre> from poetry_analysis.alliteration import count_alliterations, fetch_alliteration_symbol, find_line_alliterations  text = \"\"\"Stjerneklare Septembernat  Sees Sirius,  Sydhimlens smukkeste  Stjerne,  Solens skj\u00f8nneste S\u00f8ster,  Sv\u00e6ve saa stille,  Straale saa smukt,  Skue s\u00f8rgmodigt  Sl\u00e6gternes Strid.  Sine samlede Syner  Sender Stjernen Sirius  Sine store Sl\u00e6gtninge:  Solen, Skorpionen,  Stolte, sv\u00f8mmende Svane,  Sydkorset, Saturn,  Som straalende Stjerneskud.  Sirius ser saameget! Ser Sagas skyh\u00f8ie S\u00e6de, \u2012 Store Skagast\u00f8lstind \u2012 Som sydfor Sneh\u00e6tten staar.\"\"\"  result = find_line_alliterations(text) alliteration_count = count_alliterations(result) symbol = fetch_alliteration_symbol(result)  print(f\"Fant {alliteration_count} ord som starter p\u00e5 '{symbol}': \") print(result) <pre>Fant 52 ord som starter p\u00e5 's': \n[['stjerneklare', 'septembernat', 'sees', 'sirius', 'sydhimlens', 'smukkeste', 'stjerne', 'solens', 'skj\u00f8nneste', 's\u00f8ster', 'sv\u00e6ve', 'saa', 'stille', 'straale', 'saa', 'smukt', 'skue', 's\u00f8rgmodigt', 'sl\u00e6gternes', 'strid', 'sine', 'samlede', 'syner', 'sender', 'stjernen', 'sirius', 'sine', 'store', 'sl\u00e6gtninge', 'solen', 'skorpionen', 'stolte', 'sv\u00f8mmende', 'svane', 'sydkorset', 'saturn', 'som', 'straalende', 'stjerneskud', 'sirius', 'ser', 'saameget', 'ser', 'sagas', 'skyh\u00f8ie', 's\u00e6de', 'store', 'skagast\u00f8lstind', 'som', 'sydfor', 'sneh\u00e6tten', 'staar']]\n</pre> In\u00a0[25]: Copied! <pre>from poetry_analysis.lyrical_subject import detect_lyrical_subject\n\ndetect_lyrical_subject(text)\n</pre> from poetry_analysis.lyrical_subject import detect_lyrical_subject  detect_lyrical_subject(text) Out[25]: <pre>{'explicit_subject': True,\n 'explicit_object': True,\n 'implicit': True,\n 'deixis': False}</pre> In\u00a0[26]: Copied! <pre>import pandas as pd\n\n# Last inn i en pandas dataramme\ntextdata = pd.read_json(\"norn_poems.jsonl\", lines=True)\nmeta = pd.read_json(\"metadata.jsonl\", lines=True)\n\ndf = meta.merge(textdata, on=\"poem_id\")\n</pre> import pandas as pd  # Last inn i en pandas dataramme textdata = pd.read_json(\"norn_poems.jsonl\", lines=True) meta = pd.read_json(\"metadata.jsonl\", lines=True)  df = meta.merge(textdata, on=\"poem_id\") <p>S\u00e5 kan vi bruke funksjonen <code>tag_text</code> p\u00e5 datarammen:</p> In\u00a0[27]: Copied! <pre>from poetry_analysis.rhyme_detection import tag_text\n\ndf[\"end_rhymes\"] = df.text.apply(lambda t: list(tag_text(t)))\n</pre> from poetry_analysis.rhyme_detection import tag_text  df[\"end_rhymes\"] = df.text.apply(lambda t: list(tag_text(t))) <p>Resultatet er et n\u00f8stet hierarki av strofer og linjer og annotasjoner som h\u00f8rer til, s\u00e5 vi flater det ut med god gammeldags iterasjon over radene og <code>pandas.json_normalize</code>:</p> In\u00a0[28]: Copied! <pre>all_records = []\n\nfor _, row in df.iterrows():\n    # Normaliser annotasjonsstrukturen for hver rad\n    normalized = pd.json_normalize(\n        row[\"end_rhymes\"],\n        record_path=\"verses\",\n        meta=[\"stanza_id\", \"rhyme_scheme\"],\n    )\n    # Legg til dikt-ID s\u00e5 vi beholder koblingen til metadata\n    normalized[\"poem_id\"] = row[\"poem_id\"]\n    all_records.append(normalized)\n\n# Concatenate all records\nexpanded = pd.concat(all_records, ignore_index=True)\n</pre> all_records = []  for _, row in df.iterrows():     # Normaliser annotasjonsstrukturen for hver rad     normalized = pd.json_normalize(         row[\"end_rhymes\"],         record_path=\"verses\",         meta=[\"stanza_id\", \"rhyme_scheme\"],     )     # Legg til dikt-ID s\u00e5 vi beholder koblingen til metadata     normalized[\"poem_id\"] = row[\"poem_id\"]     all_records.append(normalized)  # Concatenate all records expanded = pd.concat(all_records, ignore_index=True) <pre>/tmp/ipykernel_28938/602871409.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  expanded = pd.concat(all_records, ignore_index=True)\n</pre> In\u00a0[12]: Copied! <pre>n_authors = df.author_name.nunique()\nn_books = df.txt_dirname.nunique()  # Unike IDer for publikasjoner\nn_poems = df.poem_id.nunique()\n\n# Antall strofer\nstanza_count = (\n    expanded.groupby([\"poem_id\", \"stanza_id\"])\n    .count()\n    .reset_index()\n    .groupby(\"poem_id\")\n    .agg(n_stanzas=(\"stanza_id\", \"count\"))\n    .reset_index()\n)\nn_stanzas = int(stanza_count.n_stanzas.sum())\n\n\n# Antall linjer\nn_lines = len(expanded)\n\n\n# Antall ord i materialet:\nn_words = expanded.tokens.apply(len).sum()\nn_types = expanded.tokens.explode().nunique()\n\n\nprint(\"Det er \")\nprint(f\"- {n_books} b\u00f8ker og \")\nprint(f\"- {n_poems} dikt i dette korpusutvalget, \")\nprint(f\"- skrevet av {n_authors} forfattere.\")\n\nprint(\"Tilsammen best\u00e5r datamaterialet av\")\nprint(f\"- {n_stanzas} strofer, \")\nprint(f\"- {n_lines} verselinjer, \")\nprint(f\"- {n_words} ord (tokens), og\")\nprint(f\"- {n_types} unike ordformer (typer).\")\n</pre> n_authors = df.author_name.nunique() n_books = df.txt_dirname.nunique()  # Unike IDer for publikasjoner n_poems = df.poem_id.nunique()  # Antall strofer stanza_count = (     expanded.groupby([\"poem_id\", \"stanza_id\"])     .count()     .reset_index()     .groupby(\"poem_id\")     .agg(n_stanzas=(\"stanza_id\", \"count\"))     .reset_index() ) n_stanzas = int(stanza_count.n_stanzas.sum())   # Antall linjer n_lines = len(expanded)   # Antall ord i materialet: n_words = expanded.tokens.apply(len).sum() n_types = expanded.tokens.explode().nunique()   print(\"Det er \") print(f\"- {n_books} b\u00f8ker og \") print(f\"- {n_poems} dikt i dette korpusutvalget, \") print(f\"- skrevet av {n_authors} forfattere.\")  print(\"Tilsammen best\u00e5r datamaterialet av\") print(f\"- {n_stanzas} strofer, \") print(f\"- {n_lines} verselinjer, \") print(f\"- {n_words} ord (tokens), og\") print(f\"- {n_types} unike ordformer (typer).\") <pre>Det er \n- 74 b\u00f8ker og \n- 3117 dikt i dette korpusutvalget, \n- skrevet av 57 forfattere.\nTilsammen best\u00e5r datamaterialet av\n- 18792 strofer, \n- 111700 verselinjer, \n- 624688 ord (tokens), og\n- 51034 unike ordformer (typer).\n</pre> In\u00a0[13]: Copied! <pre>rhyme_group = expanded.groupby([\"poem_id\", \"stanza_id\"]).agg(stanza_rhyme=(\"rhyme_tag\", \"sum\"))\nrhyme_count = rhyme_group.value_counts().to_frame().reset_index()\ncommon_rhyme_schemes = rhyme_count.head(10)\ncommon_rhyme_schemes.plot(x=\"stanza_rhyme\", y=\"count\", kind=\"barh\")\ncommon_rhyme_schemes\n</pre> rhyme_group = expanded.groupby([\"poem_id\", \"stanza_id\"]).agg(stanza_rhyme=(\"rhyme_tag\", \"sum\")) rhyme_count = rhyme_group.value_counts().to_frame().reset_index() common_rhyme_schemes = rhyme_count.head(10) common_rhyme_schemes.plot(x=\"stanza_rhyme\", y=\"count\", kind=\"barh\") common_rhyme_schemes Out[13]: stanza_rhyme count 0 abcb 2222 1 abab 2021 2 aabb 1256 3 abcd 1034 4 aa 509 5 abac 465 6 ababcdcd 465 7 ab 393 8 a 360 9 aabc 331 In\u00a0[14]: Copied! <pre>from poetry_analysis.anaphora import extract_stanza_anaphora, is_successive\n\n\ndef construct_anaphora_df(df: pd.DataFrame, anaphora_length: int = 1) -&gt; pd.DataFrame:\n    \"\"\"Extract anaphora from a stanza in a dataframe\"\"\"\n    dfs = []\n\n    for (poem_id, stanza_id), df_ in df.groupby([\"poem_id\", \"stanza_id\"]):\n        text = df_.text.dropna().tolist()\n        try:\n            stanza_anaphora = extract_stanza_anaphora(text, n_words=anaphora_length)\n        except:\n            print(text)\n        for phrase, indeces in stanza_anaphora.items():\n            if len(indeces) &lt;= 1:\n                continue\n            if all(is_successive(indeces)):\n                annotation = {\n                    \"poem_id\": poem_id,\n                    \"stanza_id\": int(stanza_id),\n                    \"line_id\": indeces,\n                    \"phrase\": phrase,\n                    \"count\": len(indeces),\n                    \"text\": [text[i] for i in indeces],\n                }\n\n                dfs.append(pd.DataFrame(annotation))\n    anaphora_df = pd.concat(dfs).reset_index(drop=True)\n    return anaphora_df\n\n\nanaphora_df = construct_anaphora_df(expanded, anaphora_length=3)\n</pre> from poetry_analysis.anaphora import extract_stanza_anaphora, is_successive   def construct_anaphora_df(df: pd.DataFrame, anaphora_length: int = 1) -&gt; pd.DataFrame:     \"\"\"Extract anaphora from a stanza in a dataframe\"\"\"     dfs = []      for (poem_id, stanza_id), df_ in df.groupby([\"poem_id\", \"stanza_id\"]):         text = df_.text.dropna().tolist()         try:             stanza_anaphora = extract_stanza_anaphora(text, n_words=anaphora_length)         except:             print(text)         for phrase, indeces in stanza_anaphora.items():             if len(indeces) &lt;= 1:                 continue             if all(is_successive(indeces)):                 annotation = {                     \"poem_id\": poem_id,                     \"stanza_id\": int(stanza_id),                     \"line_id\": indeces,                     \"phrase\": phrase,                     \"count\": len(indeces),                     \"text\": [text[i] for i in indeces],                 }                  dfs.append(pd.DataFrame(annotation))     anaphora_df = pd.concat(dfs).reset_index(drop=True)     return anaphora_df   anaphora_df = construct_anaphora_df(expanded, anaphora_length=3) In\u00a0[15]: Copied! <pre>anaphora_df.phrase.value_counts()\n</pre> anaphora_df.phrase.value_counts() Out[15]: <pre>phrase\nog det er         20\ngolgathamanden    10\nkom og hj\u00e6lp      10\njeg ser paa        9\nsyng meg um        8\n                  ..\nfagre ord som      2\ntid som har        2\naf alt som         2\ntil dig som        2\ndet var saa        2\nName: count, Length: 340, dtype: int64</pre>"},{"location":"demo/#kodeveiledning","title":"Kodeveiledning\u00b6","text":"<p>Denne notebooken gir en veiledning i ulike funksjoner <code>poetry_analysis</code> tilbyr, og en fremgangsm\u00e5te for \u00e5 bruke dem p\u00e5 st\u00f8rre tekstmaterialer</p>"},{"location":"demo/#tekstdata","title":"Tekstdata\u00b6","text":"<p>De fleste funksjonene, som henter informasjon direkte fra teksten, fungerer p\u00e5 strofe- eller linjeniv\u00e5. Disse tar ofte et rent tekstobjekt, eller en liste med <code>string</code>-objekter som argument.</p> <p>Vi kan starte med den f\u00f8rste strofen av diktet \"At jeg, at jeg har kj\u00e6rligheden m\u00f8dt.\" av Karen Nilsen, fra Kvinders sange (1895) som eksempel, og deler teksten inn i linjer:</p>"},{"location":"demo/#lyriske-trekk-gjentakelsesmnstre","title":"Lyriske trekk: gjentakelsesm\u00f8nstre\u00b6","text":""},{"location":"demo/#enderim","title":"Enderim\u00b6","text":"<p>Vi ser at enderimsm\u00f8nsteret i teksten v\u00e5r er <code>AABB</code>.</p> <p>Legg merke til at vi m\u00e5 skru p\u00e5 et flagg (<code>orthographic=True</code>) for \u00e5 markere at verselinjene er tekst, og ikke fonemisk lydskrift.</p>"},{"location":"demo/#anaforer","title":"Anaforer\u00b6","text":"<p>Anaforer er definert som fraser i starten av en linje som gjentar seg enten p\u00e5 samme linje eller i umiddelbart p\u00e5f\u00f8lgende linjer.</p> <p>Funksjonen <code>extract_anaphora</code> henter ut henholdsvis uni-, bi-, tri- og firegrammer fra p\u00e5f\u00f8lgende linjer</p>"},{"location":"demo/#alliterasjon","title":"Alliterasjon\u00b6","text":"<p>Alliterasjon er umiddelbart p\u00e5f\u00f8lgende ord som starter p\u00e5 samme konsonant.</p> <p>Eksempeltekst er f\u00f8rste side i langdiktet \"Sirius som S\u00e9er\" av Gunhild Wexelsen (1891).</p>"},{"location":"demo/#lyrisk-subjekt","title":"Lyrisk subjekt\u00b6","text":"<p>Det lyriske subjektet kan komme frem p\u00e5 mange m\u00e5ter i et dikt, noen ganger mer eksplisitt enn andre.</p> <p>Funksjonen <code>detect_lyrical_subject</code> bruker ordlister med personlige pronomen og markerer hvorvidt et eksplisitt lyrisk subjekt (\"jeg\") eller objekt (\"meg\") forekommer i teksten, implisitt (\"du\", \"vi\", \"dere\") eller indirekte via sted-/tidsdeiksis (\"her\", \"n\u00e5\", \"i morgen\")</p>"},{"location":"demo/#pa-tide-a-heve-blikket","title":"P\u00e5 tide \u00e5 heve blikket!\u00b6","text":"<p>Vi kan jo lett se gjentakelsesm\u00f8nstrene selv n\u00e5r vi ser p\u00e5 \u00e9n tekst av gangen, men hva om du har tusenvis?</p> <p>Ta for eksempel korpuset NORN Dikt som har over 3000 korrekturleste dikt og kan lastes ned fra Github:</p> <ul> <li>norn_poems.jsonl</li> <li>metadata.jsonl</li> </ul>"},{"location":"demo/#litt-statistikk-hvordan-ser-dataene-ut","title":"Litt statistikk: hvordan ser dataene ut?\u00b6","text":""},{"location":"demo/#topp-10-rimskjema","title":"Topp 10 rimskjema\u00b6","text":""},{"location":"demo/#de-vanligste-anaforene","title":"De vanligste anaforene\u00b6","text":""}]}